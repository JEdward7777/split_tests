{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba674efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,time,itertools,random\n",
    "from allosaurus.app import read_recognizer\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2f36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, so here is a generator which iterates through the names of the wavefiles and their texts\n",
    "def get_wave_names_and_texts():\n",
    "    with open( \"./bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/text\", \"rt\" ) as text_in:\n",
    "        for line in text_in:\n",
    "            if \" \" in line:\n",
    "                split_index = line.index( \"\\t\" )\n",
    "                wave_name = line[:split_index].strip()\n",
    "                text = line[split_index+1:].strip()\n",
    "                yield {'wave_name':wave_name, 'text': text }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932e26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I now want to filter out all the sentances which have less thans in \n",
    "#because I don't want to work with music or untranslatiable stuff.\n",
    "def drop_music_and_stuffs( source ):\n",
    "    for thing in source:\n",
    "        if '<' not in thing['text']:\n",
    "            yield thing\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c23d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I need the full paths to these wave files.\n",
    "def add_full_paths( source ):\n",
    "    def find_for( wave_name ):\n",
    "        search_path = './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/'\n",
    "        for root, _, files in os.walk( search_path ):\n",
    "            for file in files:\n",
    "                if file == wave_name + \".wav\":\n",
    "#                     print( f\"root is {root}\" )\n",
    "#                     print( f\"file is {file}\" )\n",
    "                    return os.path.join( root, file )\n",
    "                    \n",
    "#                 else:\n",
    "#                     print( f\"{file} isn't \\\"{wave_name + '.wav'}\\\"\") \n",
    "#                     print( f\"wave_name is \\\"{wave_name}\\\"\")\n",
    "#                     time.sleep(.2)\n",
    "        return None\n",
    "    \n",
    "    for thing in source:\n",
    "        full_path = find_for( thing['wave_name'] )\n",
    "        if full_path is not None:\n",
    "            thing['full_path'] = full_path\n",
    "            yield thing\n",
    "        else:\n",
    "            print( f\"Couldn't find {thing['wave_name']}\")\n",
    "            time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934dccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we run allo\n",
    "def add_allo( source, emit=1 ):\n",
    "    model = read_recognizer()\n",
    "    \n",
    "    for thing in source:\n",
    "        result = model.recognize( thing['full_path'], emit=emit )\n",
    "        thing['allosaurus'] = result.replace( ' ', '' )\n",
    "        yield thing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d04f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wave_name': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10', 'text': 'rais wa tanzania jakaya mrisho kikwete', 'full_path': './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10.wav', 'allosaurus': 'ʔɒl̪ɒiɪs̪iiːk͡p̚waɒt̪tʂʌŋɴdtsʌɒɴniiːjʔaɒtʂiekʰɒaɒjamәɴiːnʂɻ̩k͡p̚tʂiːəkk͡p̚uəeɪt̪tʂen', 'epitran': 'ɾais wa tanzania ʄakaja mɾiʃo kikwete'}\n",
      "{'wave_name': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100', 'text': 'yanayo andaliwa nami pendo pondo idhaa ya kiswahili', 'full_path': './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100.wav', 'allosaurus': 'ʔeɪnʌaɪɴnɪlʲɪb̞anɪðlmiːɪiːpenɴdouəpʁuəouənɴduəoviːweɪivaæɪksk͡p̚uəonjuəiːɴllʲi', 'epitran': 'janajo andaliwa nami pendo pondo iðaa ja kiswahili'}\n",
      "{'wave_name': 'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101', 'text': 'inayokutangazia moja kwa moja kutoka jijini dar es salaam tanzania', 'full_path': './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101106/SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part101.wav', 'allosaurus': 'ʔeneæʌopuətʂtɒnʌlziːv̞ʲɪenmwotʲt͡ɕoʁkoŋ̟moet̪tʂokuətʂob̞atɕiɡiːniːitʂɪɒalʲɪesɻ̩əl̪lamәtʂʰʌɴnɳәɴs̪ʌɳɴjæa', 'epitran': 'inajokutanɡazia moʄa kwa moʄa kutoka ʄiʄini ɗaɾ es salaam tanzania'}\n"
     ]
    }
   ],
   "source": [
    "#snag the epitran translation from Colin's spreadsheet\n",
    "def add_epitran( source ):\n",
    "    colin_epitran_filename = './data/ALFFA_dataset_ allosaurus vs epitran.ods'\n",
    "    #we can read directly from ods\n",
    "    #https://stackoverflow.com/questions/17834995/how-to-convert-opendocument-spreadsheets-to-a-pandas-dataframe\n",
    "    colin_epitran = pd.read_excel(colin_epitran_filename, engine=\"odf\")\n",
    "    \n",
    "    \n",
    "    for thing in source:\n",
    "        matching_rows = colin_epitran[ colin_epitran['filename'] == thing['wave_name'] ]\n",
    "        if len( matching_rows ) > 0:\n",
    "            thing['epitran'] = matching_rows['cleaned_transcript_epitran'].tolist()[0].strip()\n",
    "            yield thing\n",
    "        else:\n",
    "            print( f\"No epitran for {thing['wave_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bca7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column( source, key ):\n",
    "    for thing in source:\n",
    "        del thing[key]\n",
    "        yield thing\n",
    "\n",
    "def shuffle_it( source ):\n",
    "    source = list(source)\n",
    "    random.shuffle(source)\n",
    "    return source\n",
    "    \n",
    "def print_progress( source, total_length, skip_length=5 ):\n",
    "    start_time = datetime.now()\n",
    "    count = 0\n",
    "    for thing in source:\n",
    "        if count > 0 and count % skip_length == 0:\n",
    "            elapsed_time = datetime.now()-start_time\n",
    "            end_time = total_length/count*elapsed_time+start_time\n",
    "            print( f\"{count}/{total_length} Elapsed {elapsed_time} Estimated end time: { end_time.strftime('%m/%d/%Y, %H:%M:%S')}\")\n",
    "            \n",
    "        yield thing\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a6062a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wave_name': 'SWH-15-20110310_16k-emission_swahili_15h00_-_16h00_tu_20110310_part392', 'text': 'kwa nini kuna ugumu kwa nato kuingia moja kwa moja', 'full_path': './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-15-20110310/SWH-15-20110310_16k-emission_swahili_15h00_-_16h00_tu_20110310_part392.wav', 'allosaurus': 'xuəaɴliɴiːɪk͡p̚uəɴɒouəɡuəmәuəxuəaɒɴnɒatʂuəouəðək͡p̚uəeiɴtɕijʔəɒmuəotɕieʁkʰuəʌnmuəoɴijiaɒn', 'epitran': 'kwa nini kuna uɠumu kwa nato kuinɡia moʄa kwa moʄa'}\n",
      "{'wave_name': 'SWH-05-20101113_16k-emission_swahili_05h30_-_06h00_tu_20101113_part148', 'text': 'na ndio maana kumekuwa na umuhimu wa kufika', 'full_path': './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20101113/SWH-05-20101113_16k-emission_swahili_05h30_-_06h00_tu_20101113_part148.wav', 'allosaurus': 'teæɴnɴtɕiomanaskomeɪskuəonouəŋ̟mouːniiːŋ̟mopuəfuəixʁeɪn', 'epitran': 'na ndio maana kumekuwa na umuhimu wa kufika'}\n",
      "{'wave_name': 'SWH-05-20110321_16k-emission_swahili_05h30_-_06h00_tu_20110321_part68', 'text': 'na kueleza kuwa limefungua kurasa mpya ya demokrasi ya kweli', 'full_path': './bigdata/ALFFA_PUBLIC/ASR/SWAHILI/data/train/wav/SWH-05-20110321/SWH-05-20110321_16k-emission_swahili_05h30_-_06h00_tu_20110321_part68.wav', 'allosaurus': 'nlaʁkweɪlʲeszðʌkuəol̪lʲɪmelfɔ̃nŋɡuəokuəɾastaәnppʲjoalʲɪmouəkuəɾaɕiaðiapːuəeɪlɪi', 'epitran': 'na kueleza kuwa limefunɡua kuɾasa mpja ja ɗemokɾasi ja kweli'}\n"
     ]
    }
   ],
   "source": [
    "x = get_wave_names_and_texts()\n",
    "x = drop_music_and_stuffs( x )\n",
    "x = shuffle_it( x )\n",
    "x = list(x)\n",
    "length = len(x)\n",
    "x = add_full_paths( x )\n",
    "x = add_allo( x, emit=1.5 )\n",
    "x = add_epitran( x )\n",
    "x = print_progress( x, length )\n",
    "print( next(x) )\n",
    "print( next(x) )\n",
    "print( next(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/9423 Elapsed 0:00:09.173124 Estimated end time: 11/27/2022, 17:10:54\n",
      "10/9423 Elapsed 0:00:10.205455 Estimated end time: 11/27/2022, 15:03:03\n",
      "15/9423 Elapsed 0:00:11.265704 Estimated end time: 11/27/2022, 14:20:44\n",
      "20/9423 Elapsed 0:00:12.175580 Estimated end time: 11/27/2022, 13:58:23\n",
      "25/9423 Elapsed 0:00:13.234745 Estimated end time: 11/27/2022, 13:45:55\n",
      "30/9423 Elapsed 0:00:14.235145 Estimated end time: 11/27/2022, 13:37:18\n",
      "35/9423 Elapsed 0:00:15.158274 Estimated end time: 11/27/2022, 13:30:47\n",
      "40/9423 Elapsed 0:00:16.139981 Estimated end time: 11/27/2022, 13:26:09\n",
      "45/9423 Elapsed 0:00:17.197050 Estimated end time: 11/27/2022, 13:22:47\n",
      "50/9423 Elapsed 0:00:18.139469 Estimated end time: 11/27/2022, 13:19:45\n",
      "55/9423 Elapsed 0:00:19.044509 Estimated end time: 11/27/2022, 13:17:09\n",
      "60/9423 Elapsed 0:00:20.249767 Estimated end time: 11/27/2022, 13:15:47\n",
      "65/9423 Elapsed 0:00:21.178757 Estimated end time: 11/27/2022, 13:13:57\n",
      "70/9423 Elapsed 0:00:22.292171 Estimated end time: 11/27/2022, 13:12:47\n",
      "75/9423 Elapsed 0:00:23.449662 Estimated end time: 11/27/2022, 13:11:53\n",
      "80/9423 Elapsed 0:00:24.549807 Estimated end time: 11/27/2022, 13:10:58\n",
      "85/9423 Elapsed 0:00:25.527043 Estimated end time: 11/27/2022, 13:09:56\n",
      "90/9423 Elapsed 0:00:26.431657 Estimated end time: 11/27/2022, 13:08:54\n",
      "95/9423 Elapsed 0:00:27.550468 Estimated end time: 11/27/2022, 13:08:19\n",
      "100/9423 Elapsed 0:00:28.596786 Estimated end time: 11/27/2022, 13:07:41\n",
      "105/9423 Elapsed 0:00:29.615712 Estimated end time: 11/27/2022, 13:07:04\n",
      "110/9423 Elapsed 0:00:30.557279 Estimated end time: 11/27/2022, 13:06:24\n",
      "115/9423 Elapsed 0:00:31.597752 Estimated end time: 11/27/2022, 13:05:56\n",
      "120/9423 Elapsed 0:00:32.772914 Estimated end time: 11/27/2022, 13:05:40\n",
      "125/9423 Elapsed 0:00:33.814229 Estimated end time: 11/27/2022, 13:05:15\n",
      "130/9423 Elapsed 0:00:35.275780 Estimated end time: 11/27/2022, 13:05:23\n",
      "135/9423 Elapsed 0:00:37.200601 Estimated end time: 11/27/2022, 13:06:03\n",
      "140/9423 Elapsed 0:00:38.308117 Estimated end time: 11/27/2022, 13:05:45\n",
      "145/9423 Elapsed 0:00:39.398643 Estimated end time: 11/27/2022, 13:05:27\n",
      "150/9423 Elapsed 0:00:40.426411 Estimated end time: 11/27/2022, 13:05:06\n",
      "155/9423 Elapsed 0:00:41.391800 Estimated end time: 11/27/2022, 13:04:43\n",
      "160/9423 Elapsed 0:00:42.426889 Estimated end time: 11/27/2022, 13:04:25\n",
      "165/9423 Elapsed 0:00:43.452466 Estimated end time: 11/27/2022, 13:04:08\n",
      "170/9423 Elapsed 0:00:44.559702 Estimated end time: 11/27/2022, 13:03:56\n",
      "175/9423 Elapsed 0:00:45.588231 Estimated end time: 11/27/2022, 13:03:41\n",
      "180/9423 Elapsed 0:00:46.471267 Estimated end time: 11/27/2022, 13:03:19\n",
      "185/9423 Elapsed 0:00:47.468736 Estimated end time: 11/27/2022, 13:03:04\n",
      "190/9423 Elapsed 0:00:48.564292 Estimated end time: 11/27/2022, 13:02:55\n",
      "195/9423 Elapsed 0:00:49.594884 Estimated end time: 11/27/2022, 13:02:43\n",
      "200/9423 Elapsed 0:00:50.611663 Estimated end time: 11/27/2022, 13:02:31\n",
      "205/9423 Elapsed 0:00:51.698727 Estimated end time: 11/27/2022, 13:02:23\n",
      "210/9423 Elapsed 0:00:52.815743 Estimated end time: 11/27/2022, 13:02:16\n",
      "215/9423 Elapsed 0:00:53.960858 Estimated end time: 11/27/2022, 13:02:11\n",
      "220/9423 Elapsed 0:00:55.015120 Estimated end time: 11/27/2022, 13:02:03\n",
      "225/9423 Elapsed 0:00:55.994503 Estimated end time: 11/27/2022, 13:01:51\n",
      "230/9423 Elapsed 0:00:57.060175 Estimated end time: 11/27/2022, 13:01:44\n",
      "235/9423 Elapsed 0:00:58.346299 Estimated end time: 11/27/2022, 13:01:46\n",
      "240/9423 Elapsed 0:00:59.464250 Estimated end time: 11/27/2022, 13:01:41\n",
      "245/9423 Elapsed 0:01:00.586817 Estimated end time: 11/27/2022, 13:01:37\n",
      "250/9423 Elapsed 0:01:01.563044 Estimated end time: 11/27/2022, 13:01:27\n",
      "255/9423 Elapsed 0:01:02.723131 Estimated end time: 11/27/2022, 13:01:24\n",
      "260/9423 Elapsed 0:01:03.702312 Estimated end time: 11/27/2022, 13:01:15\n",
      "265/9423 Elapsed 0:01:04.780754 Estimated end time: 11/27/2022, 13:01:10\n",
      "270/9423 Elapsed 0:01:05.920467 Estimated end time: 11/27/2022, 13:01:07\n",
      "275/9423 Elapsed 0:01:07.027089 Estimated end time: 11/27/2022, 13:01:03\n",
      "280/9423 Elapsed 0:01:08.161685 Estimated end time: 11/27/2022, 13:01:00\n",
      "285/9423 Elapsed 0:01:09.345423 Estimated end time: 11/27/2022, 13:00:59\n",
      "290/9423 Elapsed 0:01:10.446500 Estimated end time: 11/27/2022, 13:00:55\n",
      "295/9423 Elapsed 0:01:11.383379 Estimated end time: 11/27/2022, 13:00:47\n",
      "300/9423 Elapsed 0:01:12.373090 Estimated end time: 11/27/2022, 13:00:40\n",
      "305/9423 Elapsed 0:01:13.364836 Estimated end time: 11/27/2022, 13:00:33\n",
      "310/9423 Elapsed 0:01:14.472995 Estimated end time: 11/27/2022, 13:00:30\n",
      "315/9423 Elapsed 0:01:15.863353 Estimated end time: 11/27/2022, 13:00:36\n",
      "320/9423 Elapsed 0:01:17.079651 Estimated end time: 11/27/2022, 13:00:36\n",
      "325/9423 Elapsed 0:01:18.027330 Estimated end time: 11/27/2022, 13:00:29\n",
      "330/9423 Elapsed 0:01:19.070305 Estimated end time: 11/27/2022, 13:00:24\n",
      "335/9423 Elapsed 0:01:20.100825 Estimated end time: 11/27/2022, 13:00:20\n",
      "340/9423 Elapsed 0:01:21.193365 Estimated end time: 11/27/2022, 13:00:17\n",
      "345/9423 Elapsed 0:01:22.324694 Estimated end time: 11/27/2022, 13:00:15\n",
      "350/9423 Elapsed 0:01:23.331736 Estimated end time: 11/27/2022, 13:00:10\n",
      "355/9423 Elapsed 0:01:24.396655 Estimated end time: 11/27/2022, 13:00:07\n",
      "360/9423 Elapsed 0:01:25.552441 Estimated end time: 11/27/2022, 13:00:06\n",
      "365/9423 Elapsed 0:01:26.919977 Estimated end time: 11/27/2022, 13:00:10\n",
      "370/9423 Elapsed 0:01:28.167721 Estimated end time: 11/27/2022, 13:00:12\n",
      "375/9423 Elapsed 0:01:29.235966 Estimated end time: 11/27/2022, 13:00:09\n",
      "380/9423 Elapsed 0:01:30.213706 Estimated end time: 11/27/2022, 13:00:03\n",
      "385/9423 Elapsed 0:01:31.231026 Estimated end time: 11/27/2022, 12:59:59\n",
      "390/9423 Elapsed 0:01:32.372202 Estimated end time: 11/27/2022, 12:59:58\n",
      "395/9423 Elapsed 0:01:33.318572 Estimated end time: 11/27/2022, 12:59:53\n",
      "400/9423 Elapsed 0:01:34.705061 Estimated end time: 11/27/2022, 12:59:57\n",
      "405/9423 Elapsed 0:01:35.679288 Estimated end time: 11/27/2022, 12:59:53\n",
      "410/9423 Elapsed 0:01:37.171815 Estimated end time: 11/27/2022, 13:00:00\n"
     ]
    }
   ],
   "source": [
    "x = get_wave_names_and_texts()\n",
    "x = drop_music_and_stuffs( x )\n",
    "x = shuffle_it( x )\n",
    "x = list(x)\n",
    "length = len(x)\n",
    "x = add_full_paths( x )\n",
    "x = add_allo( x, emit=1.5 )\n",
    "x = add_epitran( x )\n",
    "x = print_progress( x, length )\n",
    "x = drop_column( x, 'full_path' )\n",
    "\n",
    "# #make sure it works first.\n",
    "# x = [next(x), next(x), next(x), next(x)]\n",
    "\n",
    "#now I need to save it back out.\n",
    "pandas_to_save = pd.DataFrame.from_records( x )\n",
    "\n",
    "\n",
    "expanded_epitran_filename = './data/ALFFA_dataset_more_phonemes.ods'\n",
    "\n",
    "with pd.ExcelWriter(expanded_epitran_filename, engine=\"odf\") as writer:\n",
    "    pandas_to_save.to_excel(writer, index=False)  \n",
    "\n",
    "print( \"done. :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf88ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "be5677814406bd98beb96b7f03230875f8ad7c187a6b9fdeaa828c987580211e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
